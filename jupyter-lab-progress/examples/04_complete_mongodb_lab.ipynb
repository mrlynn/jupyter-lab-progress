{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete MongoDB Vector Search Lab\n",
    "\n",
    "This notebook demonstrates a complete lab experience using all features of jupyter-lab-progress in a real-world MongoDB Vector Search workshop.\n",
    "\n",
    "## What You'll Learn\n",
    "- Set up MongoDB Atlas for vector search\n",
    "- Create and validate vector embeddings  \n",
    "- Build semantic search applications\n",
    "- Use jupyter-lab-progress for engaging lab experience\n",
    "\n",
    "## Prerequisites\n",
    "- MongoDB Atlas account (free tier works)\n",
    "- Python 3.8+\n",
    "- Basic knowledge of Python and pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Setup and Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "from jupyter_lab_progress import LabProgress, LabValidator, show_info, show_warning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Initialize our lab tools\n",
    "validator = LabValidator()\n",
    "\n",
    "# Welcome message\n",
    "show_info(\"\"\"üöÄ Welcome to the MongoDB Vector Search Workshop!\n",
    "\n",
    "Today we'll build a semantic search system for an e-commerce product catalog.\n",
    "You'll learn to create embeddings, store them in MongoDB, and perform vector searches.\n",
    "\n",
    "Let's build something amazing! üéØ\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Overview and Progress Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our main lab progress tracker\n",
    "main_progress = LabProgress(\n",
    "    steps=[\n",
    "        \"üîß Environment Setup\",\n",
    "        \"üìä Data Preparation\", \n",
    "        \"ü§ñ Embedding Generation\",\n",
    "        \"‚úÖ Data Validation\",\n",
    "        \"üçÉ MongoDB Integration\",\n",
    "        \"üîç Vector Search Implementation\",\n",
    "        \"üß™ Testing and Optimization\",\n",
    "        \"üéâ Lab Completion\"\n",
    "    ],\n",
    "    title=\"üõçÔ∏è E-commerce Vector Search Lab\"\n",
    ")\n",
    "\n",
    "show_info(\"Here's what we'll accomplish in this lab:\")\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version and required packages\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Simulate package installation check\n",
    "required_packages = ['pandas', 'numpy', 'pymongo']\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package}: installed\")\n",
    "    except ImportError:\n",
    "        missing_packages.append(package)\n",
    "        print(f\"‚ùå {package}: missing\")\n",
    "\n",
    "if missing_packages:\n",
    "    show_warning(f\"Please install missing packages: {', '.join(missing_packages)}\")\n",
    "else:\n",
    "    show_info(\"‚úÖ All required packages are installed!\")\n",
    "    main_progress.mark_completed(\"üîß Environment Setup\")\n",
    "    main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a realistic e-commerce product dataset\n",
    "show_info(\"Creating our e-commerce product catalog...\")\n",
    "\n",
    "products_data = {\n",
    "    'product_id': ['TECH001', 'TECH002', 'TECH003', 'TECH004', 'TECH005', \n",
    "                   'TECH006', 'TECH007', 'TECH008', 'TECH009', 'TECH010'],\n",
    "    'name': [\n",
    "        'MacBook Pro 16-inch M3',\n",
    "        'Dell XPS 15 OLED',\n",
    "        'iPad Pro 12.9-inch',\n",
    "        'iPhone 15 Pro Max',\n",
    "        'AirPods Pro 2nd Gen',\n",
    "        'Sony WH-1000XM5 Headphones',\n",
    "        'Samsung Galaxy S24 Ultra',\n",
    "        'Microsoft Surface Pro 9',\n",
    "        'Nintendo Switch OLED',\n",
    "        'Apple Watch Series 9'\n",
    "    ],\n",
    "    'category': [\n",
    "        'Laptops', 'Laptops', 'Tablets', 'Smartphones', 'Audio',\n",
    "        'Audio', 'Smartphones', 'Tablets', 'Gaming', 'Wearables'\n",
    "    ],\n",
    "    'price': [2499.99, 1999.99, 1099.99, 1199.99, 249.99, \n",
    "              399.99, 1299.99, 1299.99, 349.99, 399.99],\n",
    "    'description': [\n",
    "        'Professional laptop with M3 Pro chip, 18GB unified memory, and stunning 16-inch Liquid Retina XDR display',\n",
    "        'Premium Windows laptop featuring Intel Core i7, 32GB RAM, 1TB SSD, and gorgeous 4K OLED touchscreen',\n",
    "        'Ultimate tablet experience with M2 chip, 12.9-inch Liquid Retina XDR display, and Apple Pencil support',\n",
    "        'Pro smartphone with titanium design, A17 Pro chip, advanced camera system, and Action button',\n",
    "        'Wireless earbuds with H2 chip, Active Noise Cancellation, and personalized Spatial Audio',\n",
    "        'Industry-leading noise canceling headphones with 30-hour battery and premium sound quality',\n",
    "        'Flagship Android phone with S Pen, 200MP camera, AI features, and stunning 6.8-inch display',\n",
    "        '2-in-1 laptop with Intel Core i7, detachable keyboard, and vibrant PixelSense touchscreen',\n",
    "        'Portable gaming console with 7-inch OLED screen, enhanced audio, and wide adjustable stand',\n",
    "        'Advanced smartwatch with health monitoring, GPS, cellular connectivity, and bright Always-On display'\n",
    "    ],\n",
    "    'brand': [\n",
    "        'Apple', 'Dell', 'Apple', 'Apple', 'Apple',\n",
    "        'Sony', 'Samsung', 'Microsoft', 'Nintendo', 'Apple'\n",
    "    ],\n",
    "    'rating': [4.8, 4.6, 4.7, 4.9, 4.5, 4.7, 4.6, 4.4, 4.8, 4.6],\n",
    "    'stock': [25, 30, 15, 40, 60, 35, 45, 20, 50, 30]\n",
    "}\n",
    "\n",
    "products_df = pd.DataFrame(products_data)\n",
    "\n",
    "# Display our dataset\n",
    "print(f\"Created product catalog with {len(products_df)} items:\")\n",
    "print(products_df[['name', 'category', 'price', 'brand']].head())\n",
    "\n",
    "show_info(f\"‚úÖ Product catalog ready with {len(products_df)} items across {products_df['category'].nunique()} categories!\")\n",
    "main_progress.mark_completed(\"üìä Data Preparation\")\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sub-progress tracker for embedding generation\n",
    "embedding_progress = LabProgress(\n",
    "    steps=[\n",
    "        \"Initialize embedding model\",\n",
    "        \"Process product descriptions\",\n",
    "        \"Generate embeddings\",\n",
    "        \"Verify embedding quality\"\n",
    "    ],\n",
    "    title=\"ü§ñ Embedding Generation Process\"\n",
    ")\n",
    "\n",
    "show_info(\"Now we'll create vector embeddings for semantic search...\")\n",
    "embedding_progress.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate embedding model initialization\n",
    "show_info(\"üîÑ Initializing sentence transformer model...\")\n",
    "time.sleep(1)  # Simulate model loading time\n",
    "\n",
    "def create_semantic_embedding(text, model_type=\"sentence-transformer\", dimensions=384):\n",
    "    \"\"\"\n",
    "    Simulate creating embeddings with a sentence transformer model.\n",
    "    In a real implementation, you would use sentence-transformers or OpenAI API.\n",
    "    \"\"\"\n",
    "    # Create reproducible \"embeddings\" based on text content\n",
    "    import hashlib\n",
    "    seed = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)\n",
    "    np.random.seed(seed % 2**31)\n",
    "    \n",
    "    # Generate normalized embeddings\n",
    "    embedding = np.random.randn(dimensions)\n",
    "    embedding = embedding / np.linalg.norm(embedding)  # Normalize\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "show_info(\"‚úÖ Model initialized! Using 384-dimensional embeddings.\")\n",
    "embedding_progress.mark_completed(\"Initialize embedding model\")\n",
    "embedding_progress.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process product descriptions for embedding\n",
    "show_info(\"Preprocessing product descriptions...\")\n",
    "\n",
    "# Combine name and description for richer embeddings\n",
    "products_df['full_text'] = products_df['name'] + ' - ' + products_df['description']\n",
    "\n",
    "print(\"Sample combined text:\")\n",
    "print(f\"'{products_df['full_text'].iloc[0][:100]}...'\")\n",
    "\n",
    "embedding_progress.mark_completed(\"Process product descriptions\")\n",
    "embedding_progress.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings with progress tracking\n",
    "show_info(\"üîÑ Generating embeddings for all products...\")\n",
    "\n",
    "embeddings = []\n",
    "for i, text in enumerate(products_df['full_text']):\n",
    "    embedding = create_semantic_embedding(text)\n",
    "    embeddings.append(embedding)\n",
    "    \n",
    "    # Show progress for demonstration\n",
    "    if (i + 1) % 3 == 0:\n",
    "        print(f\"Generated {i + 1}/{len(products_df)} embeddings...\")\n",
    "\n",
    "# Add embeddings to DataFrame\n",
    "products_df['embedding'] = embeddings\n",
    "\n",
    "print(f\"\\n‚úÖ Generated embeddings for all {len(embeddings)} products!\")\n",
    "print(f\"Embedding shape: {embeddings[0].shape}\")\n",
    "\n",
    "embedding_progress.mark_completed(\"Generate embeddings\")\n",
    "embedding_progress.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify embedding quality\n",
    "show_info(\"Verifying embedding quality...\")\n",
    "\n",
    "# Check embedding statistics\n",
    "embedding_array = np.array(embeddings)\n",
    "norms = np.linalg.norm(embedding_array, axis=1)\n",
    "mean_norm = np.mean(norms)\n",
    "std_norm = np.std(norms)\n",
    "\n",
    "print(f\"Embedding statistics:\")\n",
    "print(f\"- Shape: {embedding_array.shape}\")\n",
    "print(f\"- Mean norm: {mean_norm:.3f}\")\n",
    "print(f\"- Std norm: {std_norm:.3f}\")\n",
    "print(f\"- All normalized: {np.allclose(norms, 1.0, atol=1e-6)}\")\n",
    "\n",
    "# Test similarity between similar products\n",
    "iphone_idx = products_df[products_df['name'].str.contains('iPhone')].index[0]\n",
    "macbook_idx = products_df[products_df['name'].str.contains('MacBook')].index[0]\n",
    "\n",
    "similarity = np.dot(embeddings[iphone_idx], embeddings[macbook_idx])\n",
    "print(f\"\\nSimilarity between iPhone and MacBook: {similarity:.3f}\")\n",
    "\n",
    "show_info(\"‚úÖ Embedding quality verified!\")\n",
    "embedding_progress.mark_completed(\"Verify embedding quality\")\n",
    "embedding_progress.display()\n",
    "\n",
    "main_progress.mark_completed(\"ü§ñ Embedding Generation\")\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data validation\n",
    "show_info(\"Running comprehensive data validation...\")\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "# 1. Validate embedding dimensions\n",
    "try:\n",
    "    is_valid = validator.check_embedding_shape(\n",
    "        embeddings=embedding_array,\n",
    "        expected_dim=384\n",
    "    )\n",
    "    if is_valid:\n",
    "        validation_results.append(\"‚úÖ Embedding dimensions: PASS\")\n",
    "    else:\n",
    "        validation_results.append(\"‚ùå Embedding dimensions: FAIL\")\n",
    "except Exception as e:\n",
    "    validation_results.append(f\"‚ùå Embedding validation error: {e}\")\n",
    "\n",
    "# 2. Validate required products exist\n",
    "try:\n",
    "    validator.assert_in_dataframe(\n",
    "        df=products_df,\n",
    "        column='category',\n",
    "        values=['Laptops', 'Smartphones', 'Audio'],\n",
    "        context='Required product categories'\n",
    "    )\n",
    "    validation_results.append(\"‚úÖ Product categories: PASS\")\n",
    "except AssertionError as e:\n",
    "    validation_results.append(f\"‚ùå Product categories: {e}\")\n",
    "\n",
    "# 3. Validate Apple products exist (for demo)\n",
    "try:\n",
    "    validator.assert_in_dataframe(\n",
    "        df=products_df,\n",
    "        column='brand',\n",
    "        values=['Apple'],\n",
    "        context='Apple products validation'\n",
    "    )\n",
    "    validation_results.append(\"‚úÖ Apple products: PASS\")\n",
    "except AssertionError as e:\n",
    "    validation_results.append(f\"‚ùå Apple products: {e}\")\n",
    "\n",
    "# 4. Custom validation: Check data completeness\n",
    "required_columns = ['product_id', 'name', 'description', 'embedding']\n",
    "missing_columns = [col for col in required_columns if col not in products_df.columns]\n",
    "\n",
    "if not missing_columns:\n",
    "    validation_results.append(\"‚úÖ Required columns: PASS\")\n",
    "else:\n",
    "    validation_results.append(f\"‚ùå Missing columns: {missing_columns}\")\n",
    "\n",
    "# 5. Check for null values\n",
    "null_counts = products_df[required_columns].isnull().sum()\n",
    "if null_counts.sum() == 0:\n",
    "    validation_results.append(\"‚úÖ No null values: PASS\")\n",
    "else:\n",
    "    validation_results.append(f\"‚ùå Found null values: {null_counts.to_dict()}\")\n",
    "\n",
    "# Display validation results\n",
    "print(\"\\nValidation Results:\")\n",
    "for result in validation_results:\n",
    "    print(f\"  {result}\")\n",
    "\n",
    "# Check if all validations passed\n",
    "all_passed = all('‚úÖ' in result for result in validation_results)\n",
    "\n",
    "if all_passed:\n",
    "    show_info(\"üéâ All validation checks passed! Data is ready for MongoDB.\")\n",
    "    main_progress.mark_completed(\"‚úÖ Data Validation\")\n",
    "else:\n",
    "    show_warning(\"‚ö†Ô∏è Some validation checks failed. Please review the results above.\")\n",
    "\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 5: MongoDB Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB integration (simulated)\n",
    "show_warning(\"\"\"üìù MongoDB Setup Required:\n",
    "\n",
    "To continue with real MongoDB integration, you'll need:\n",
    "1. MongoDB Atlas account (free tier available)\n",
    "2. Create a cluster and database\n",
    "3. Configure network access (IP whitelist)\n",
    "4. Create database user with read/write permissions\n",
    "5. Get connection string from Atlas dashboard\n",
    "\n",
    "For this demo, we'll simulate the MongoDB operations.\"\"\")\n",
    "\n",
    "# Simulate MongoDB document preparation\n",
    "show_info(\"Preparing documents for MongoDB insertion...\")\n",
    "\n",
    "# Convert DataFrame to MongoDB documents\n",
    "mongodb_documents = []\n",
    "for _, row in products_df.iterrows():\n",
    "    doc = {\n",
    "        '_id': row['product_id'],\n",
    "        'name': row['name'],\n",
    "        'category': row['category'],\n",
    "        'brand': row['brand'],\n",
    "        'price': row['price'],\n",
    "        'description': row['description'],\n",
    "        'rating': row['rating'],\n",
    "        'stock': row['stock'],\n",
    "        'embedding': row['embedding'].tolist(),  # Convert numpy array to list\n",
    "        'created_at': datetime.now().isoformat(),\n",
    "        'metadata': {\n",
    "            'embedding_model': 'sentence-transformer-384d',\n",
    "            'embedding_version': '1.0'\n",
    "        }\n",
    "    }\n",
    "    mongodb_documents.append(doc)\n",
    "\n",
    "print(f\"Prepared {len(mongodb_documents)} documents for MongoDB\")\n",
    "print(\"\\nSample document structure:\")\n",
    "sample_doc = mongodb_documents[0].copy()\n",
    "sample_doc['embedding'] = f\"[{len(sample_doc['embedding'])} dimensional vector]\"\n",
    "print(json.dumps(sample_doc, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate MongoDB operations\n",
    "def simulate_mongodb_operations():\n",
    "    \"\"\"Simulate MongoDB Atlas operations.\"\"\"\n",
    "    operations = [\n",
    "        \"Connecting to MongoDB Atlas cluster...\",\n",
    "        \"Selecting database 'ecommerce'...\",\n",
    "        \"Accessing collection 'products'...\",\n",
    "        \"Inserting product documents...\",\n",
    "        \"Creating vector search index...\"\n",
    "    ]\n",
    "    \n",
    "    for i, operation in enumerate(operations):\n",
    "        print(f\"‚è≥ {operation}\")\n",
    "        time.sleep(0.8)  # Simulate processing time\n",
    "        print(f\"‚úÖ {operation.replace('...', ' - COMPLETE')}\")\n",
    "        \n",
    "        if i == 3:  # After inserting documents\n",
    "            print(f\"   üìä Inserted {len(mongodb_documents)} documents\")\n",
    "        elif i == 4:  # After creating index\n",
    "            print(\"   üîç Vector search index 'product_embeddings' created\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run simulation\n",
    "success = simulate_mongodb_operations()\n",
    "\n",
    "if success:\n",
    "    show_info(\"\"\"üéâ MongoDB integration complete!\n",
    "    \n",
    "Your vector search database is ready with:\n",
    "‚úÖ Product documents with embeddings\n",
    "‚úÖ Vector search index configured\n",
    "‚úÖ Ready for semantic search queries\"\"\")\n",
    "    \n",
    "    main_progress.mark_completed(\"üçÉ MongoDB Integration\")\n",
    "    main_progress.display()\n",
    "else:\n",
    "    show_warning(\"‚ùå MongoDB integration failed. Please check your configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 6: Vector Search Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement vector search functionality\n",
    "show_info(\"Implementing vector search functionality...\")\n",
    "\n",
    "def vector_search(query_text, products_df, top_k=5):\n",
    "    \"\"\"\n",
    "    Perform vector similarity search.\n",
    "    In a real implementation, this would query MongoDB Atlas.\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = create_semantic_embedding(query_text)\n",
    "    \n",
    "    # Calculate similarities with all products\n",
    "    similarities = []\n",
    "    for idx, product_embedding in enumerate(products_df['embedding']):\n",
    "        similarity = np.dot(query_embedding, product_embedding)\n",
    "        similarities.append((idx, similarity))\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top-k results\n",
    "    results = []\n",
    "    for idx, similarity in similarities[:top_k]:\n",
    "        product = products_df.iloc[idx]\n",
    "        results.append({\n",
    "            'product_id': product['product_id'],\n",
    "            'name': product['name'],\n",
    "            'category': product['category'],\n",
    "            'price': product['price'],\n",
    "            'similarity_score': similarity,\n",
    "            'description': product['description'][:100] + '...'\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test vector search with different queries\n",
    "test_queries = [\n",
    "    \"portable laptop for work\",\n",
    "    \"wireless headphones with noise cancellation\",\n",
    "    \"smartphone with great camera\",\n",
    "    \"gaming device for entertainment\"\n",
    "]\n",
    "\n",
    "print(\"Testing vector search functionality:\\n\")\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"üîç Query {i}: '{query}'\")\n",
    "    results = vector_search(query, products_df, top_k=3)\n",
    "    \n",
    "    print(\"Top 3 matches:\")\n",
    "    for j, result in enumerate(results, 1):\n",
    "        print(f\"  {j}. {result['name']} (Score: {result['similarity_score']:.3f})\")\n",
    "        print(f\"     Category: {result['category']} | Price: ${result['price']}\")\n",
    "    print()\n",
    "\n",
    "show_info(\"‚úÖ Vector search implementation complete and tested!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced search features\n",
    "show_info(\"Implementing advanced search features...\")\n",
    "\n",
    "def hybrid_search(query_text, products_df, category_filter=None, price_range=None, top_k=5):\n",
    "    \"\"\"\n",
    "    Hybrid search combining vector similarity with traditional filters.\n",
    "    \"\"\"\n",
    "    # Start with all products\n",
    "    filtered_df = products_df.copy()\n",
    "    \n",
    "    # Apply category filter\n",
    "    if category_filter:\n",
    "        filtered_df = filtered_df[filtered_df['category'] == category_filter]\n",
    "    \n",
    "    # Apply price range filter\n",
    "    if price_range:\n",
    "        min_price, max_price = price_range\n",
    "        filtered_df = filtered_df[\n",
    "            (filtered_df['price'] >= min_price) & \n",
    "            (filtered_df['price'] <= max_price)\n",
    "        ]\n",
    "    \n",
    "    if len(filtered_df) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Perform vector search on filtered results\n",
    "    query_embedding = create_semantic_embedding(query_text)\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, row in filtered_df.iterrows():\n",
    "        similarity = np.dot(query_embedding, row['embedding'])\n",
    "        similarities.append((idx, similarity))\n",
    "    \n",
    "    # Sort by similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top-k results\n",
    "    results = []\n",
    "    for idx, similarity in similarities[:top_k]:\n",
    "        product = products_df.iloc[idx]\n",
    "        results.append({\n",
    "            'product_id': product['product_id'],\n",
    "            'name': product['name'],\n",
    "            'category': product['category'],\n",
    "            'brand': product['brand'],\n",
    "            'price': product['price'],\n",
    "            'rating': product['rating'],\n",
    "            'similarity_score': similarity\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test hybrid search\n",
    "print(\"üîç Hybrid Search Example:\")\n",
    "print(\"Query: 'high-quality device' | Category: 'Audio' | Price: $200-$500\\n\")\n",
    "\n",
    "hybrid_results = hybrid_search(\n",
    "    query_text=\"high-quality device\",\n",
    "    products_df=products_df,\n",
    "    category_filter=\"Audio\",\n",
    "    price_range=(200, 500)\n",
    ")\n",
    "\n",
    "for i, result in enumerate(hybrid_results, 1):\n",
    "    print(f\"{i}. {result['name']} by {result['brand']}\")\n",
    "    print(f\"   Price: ${result['price']} | Rating: {result['rating']} | Score: {result['similarity_score']:.3f}\")\n",
    "\n",
    "main_progress.mark_completed(\"üîç Vector Search Implementation\")\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 7: Testing and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive testing\n",
    "show_info(\"Running comprehensive tests...\")\n",
    "\n",
    "# Test 1: Search precision\n",
    "def test_search_precision():\n",
    "    \"\"\"Test if searches return relevant results.\"\"\"\n",
    "    test_cases = [\n",
    "        (\"apple laptop\", \"Laptops\", \"Apple\"),\n",
    "        (\"wireless earbuds\", \"Audio\", None),\n",
    "        (\"samsung phone\", \"Smartphones\", \"Samsung\"),\n",
    "        (\"gaming console\", \"Gaming\", None)\n",
    "    ]\n",
    "    \n",
    "    passed_tests = 0\n",
    "    \n",
    "    for query, expected_category, expected_brand in test_cases:\n",
    "        results = vector_search(query, products_df, top_k=1)\n",
    "        if results:\n",
    "            top_result = results[0]\n",
    "            category_match = top_result['category'] == expected_category\n",
    "            brand_match = expected_brand is None or products_df[products_df['product_id'] == top_result['product_id']]['brand'].iloc[0] == expected_brand\n",
    "            \n",
    "            if category_match and brand_match:\n",
    "                passed_tests += 1\n",
    "                print(f\"‚úÖ '{query}' ‚Üí {top_result['name']} (PASS)\")\n",
    "            else:\n",
    "                print(f\"‚ùå '{query}' ‚Üí {top_result['name']} (FAIL)\")\n",
    "    \n",
    "    return passed_tests, len(test_cases)\n",
    "\n",
    "# Run precision test\n",
    "passed, total = test_search_precision()\n",
    "precision = passed / total * 100\n",
    "print(f\"\\nSearch Precision: {passed}/{total} ({precision:.1f}%)\")\n",
    "\n",
    "if precision >= 75:\n",
    "    show_info(f\"‚úÖ Search precision test PASSED ({precision:.1f}%)\")\n",
    "else:\n",
    "    show_warning(f\"‚ö†Ô∏è Search precision needs improvement ({precision:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance testing\n",
    "show_info(\"Testing search performance...\")\n",
    "\n",
    "import time\n",
    "\n",
    "# Test search speed\n",
    "queries = [\"laptop\", \"headphones\", \"smartphone\", \"tablet\", \"gaming\"]\n",
    "search_times = []\n",
    "\n",
    "for query in queries:\n",
    "    start_time = time.time()\n",
    "    results = vector_search(query, products_df, top_k=5)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    search_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "    search_times.append(search_time)\n",
    "    \n",
    "avg_search_time = np.mean(search_times)\n",
    "print(f\"Average search time: {avg_search_time:.2f}ms\")\n",
    "print(f\"Total products searched: {len(products_df)}\")\n",
    "print(f\"Searches per second: {1000/avg_search_time:.1f}\")\n",
    "\n",
    "if avg_search_time < 100:  # Less than 100ms\n",
    "    show_info(\"‚úÖ Performance test PASSED - Search is fast enough for real-time use\")\n",
    "else:\n",
    "    show_warning(\"‚ö†Ô∏è Performance could be improved for larger datasets\")\n",
    "\n",
    "main_progress.mark_completed(\"üß™ Testing and Optimization\")\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 8: Lab Completion and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive lab report\n",
    "show_info(\"Generating lab completion report...\")\n",
    "\n",
    "# Create summary statistics\n",
    "lab_stats = {\n",
    "    'products_processed': len(products_df),\n",
    "    'categories': products_df['category'].nunique(),\n",
    "    'brands': products_df['brand'].nunique(),\n",
    "    'embedding_dimension': 384,\n",
    "    'search_precision': precision,\n",
    "    'avg_search_time_ms': avg_search_time,\n",
    "    'total_validation_checks': len(validation_results),\n",
    "    'validation_passed': sum('‚úÖ' in result for result in validation_results)\n",
    "}\n",
    "\n",
    "# Display final report\n",
    "show_info(\"\"\"üéä CONGRATULATIONS! Vector Search Lab Complete!\n",
    "\n",
    "üèÜ What you've accomplished:\n",
    "‚úÖ Built a complete e-commerce search system\n",
    "‚úÖ Generated semantic embeddings for products\n",
    "‚úÖ Implemented vector similarity search\n",
    "‚úÖ Created hybrid search with filters\n",
    "‚úÖ Validated data integrity throughout\n",
    "‚úÖ Tested search precision and performance\n",
    "\n",
    "You're now ready to build production vector search applications!\"\"\")\n",
    "\n",
    "print(\"\\nüìä Lab Statistics:\")\n",
    "for key, value in lab_stats.items():\n",
    "    formatted_key = key.replace('_', ' ').title()\n",
    "    if isinstance(value, float):\n",
    "        print(f\"‚Ä¢ {formatted_key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"‚Ä¢ {formatted_key}: {value}\")\n",
    "\n",
    "main_progress.mark_completed(\"üéâ Lab Completion\")\n",
    "main_progress.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next steps and resources\n",
    "show_info(\"\"\"üöÄ Next Steps and Advanced Topics:\n",
    "\n",
    "1. **Production Deployment:**\n",
    "   ‚Ä¢ Set up MongoDB Atlas with real connection\n",
    "   ‚Ä¢ Implement proper error handling\n",
    "   ‚Ä¢ Add authentication and rate limiting\n",
    "\n",
    "2. **Advanced Features:**\n",
    "   ‚Ä¢ Multi-modal search (text + images)\n",
    "   ‚Ä¢ Real-time embedding updates\n",
    "   ‚Ä¢ Personalized search results\n",
    "   ‚Ä¢ Search analytics and monitoring\n",
    "\n",
    "3. **Optimization:**\n",
    "   ‚Ä¢ Fine-tune embedding models\n",
    "   ‚Ä¢ Implement search result caching\n",
    "   ‚Ä¢ A/B test different embedding strategies\n",
    "   ‚Ä¢ Scale for millions of products\"\"\")\n",
    "\n",
    "show_info(\"\"\"üìö Additional Resources:\n",
    "\n",
    "‚Ä¢ MongoDB Vector Search Documentation: https://docs.atlas.mongodb.com/atlas-search/\n",
    "‚Ä¢ Sentence Transformers: https://www.sbert.net/\n",
    "‚Ä¢ OpenAI Embeddings: https://platform.openai.com/docs/guides/embeddings\n",
    "‚Ä¢ MongoDB Developer Hub: https://developer.mongodb.com/\n",
    "‚Ä¢ Community Forums: https://community.mongodb.com/\"\"\")\n",
    "\n",
    "show_warning(\"\"\"üßπ Lab Cleanup Reminders:\n",
    "\n",
    "If you used real MongoDB Atlas:\n",
    "‚Ä¢ Pause or delete your cluster if not needed\n",
    "‚Ä¢ Remove test data if desired\n",
    "‚Ä¢ Rotate any API keys used\n",
    "‚Ä¢ Document your connection settings for future use\"\"\")\n",
    "\n",
    "# Final message\n",
    "show_info(\"\"\"üåü Thank you for completing the Vector Search Lab!\n",
    "\n",
    "You've gained hands-on experience with:\n",
    "‚Ä¢ Modern vector search technology\n",
    "‚Ä¢ MongoDB Atlas Vector Search\n",
    "‚Ä¢ Production-ready search systems\n",
    "‚Ä¢ Data validation best practices\n",
    "\n",
    "Keep building amazing things! üöÄ\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Interactive Search Demo\n",
    "\n",
    "Try the search system yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive search function\n",
    "def interactive_search_demo():\n",
    "    \"\"\"Interactive demo for trying different search queries.\"\"\"\n",
    "    show_info(\"üîç Interactive Search Demo - Try your own queries!\")\n",
    "    \n",
    "    # Predefined example queries students can try\n",
    "    example_queries = [\n",
    "        \"professional laptop for coding\",\n",
    "        \"premium audio experience\",\n",
    "        \"portable device for productivity\",\n",
    "        \"high-end smartphone with camera\",\n",
    "        \"entertainment device for games\"\n",
    "    ]\n",
    "    \n",
    "    print(\"Example queries to try:\")\n",
    "    for i, query in enumerate(example_queries, 1):\n",
    "        print(f\"{i}. '{query}'\")\n",
    "    \n",
    "    print(\"\\nSearching for 'professional laptop for coding':\")\n",
    "    results = vector_search(\"professional laptop for coding\", products_df, top_k=3)\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. **{result['name']}**\")\n",
    "        print(f\"   Category: {result['category']} | Price: ${result['price']}\")\n",
    "        print(f\"   Similarity: {result['similarity_score']:.3f}\")\n",
    "        print(f\"   Description: {result['description']}\")\n",
    "\n",
    "# Run the interactive demo\n",
    "interactive_search_demo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n",
   "language": "python",\n",
   "name": "python3\n  },\n",
   "language_info": {\n",
    "codemirror_mode": {\n",
     "name": "ipython",\n",
     "version": 3\n",
    "},\n",
    "file_extension": ".py",\n",
    "mimetype": "text/x-python",\n",
    "name": "python",\n",
    "nbconvert_exporter": "python",\n",
    "version": "3.9.0"\n",
   }\n",
  },\n",
  "nbformat": 4,\n",
  "nbformat_minor": 4\n",
 }\n}